{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get files from Zotero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, basename, splitext\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from random import shuffle, seed\n",
    "\n",
    "from pyzotero import zotero\n",
    "\n",
    "from secrets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = join('data', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that does the actual download of the PDFs using Zotero's API.\n",
    "\n",
    "First, we need to get all of the collections in the Zotero Library. Collections are like sub-folders in the library. We will be looking for a collection with the given name.\n",
    "\n",
    "Next, we will get all of the items in a collection with a given tag. We have been tagging items with a \"Rel-Yes\" or \"Rel-No\" when we determine if the item is relevant to the study or not.\n",
    "\n",
    "Finally, we can get the PDF attachment associated with the item. An item may have more than one attachment (PDF, HTML, etc.) underneath it. However, for our current purpose we are only concerned with the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pdfs(output_dir, collection_name, tag):\n",
    "\n",
    "    # Creat the output directory\n",
    "    path = join(output_dir, collection_name, tag)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Connect to Zotero\n",
    "    zot = zotero.Zotero(secrets, 'group', user_key)\n",
    "\n",
    "    # Get the collection of interest and it's key\n",
    "    collections = {c['data']['name']: c for c in zot.collections()}\n",
    "    collection = collections[collection_name]\n",
    "    key = collection['key']\n",
    "\n",
    "    # Now get the items in the collection that have the given tag\n",
    "    items = [d for d in zot.everything(zot.collection_items(key, tag=tag))]\n",
    "    # items = [d for d in zot.collection_items(key, tag=tag, limit=3)]\n",
    "\n",
    "    # Get the PDF attachment for each item and save it to the class directory\n",
    "    for item in items:\n",
    "        # An item's attachments\n",
    "        children = [c for c in zot.children(item['key'])]\n",
    "\n",
    "        # Just get the PDFs\n",
    "        pdfs = [c for c in children\n",
    "                if c['data'].get('contentType') == 'application/pdf']\n",
    "\n",
    "        # Handle when there are no attachments\n",
    "        if not children:\n",
    "            print('\\nMISSING DOCUMENTS {}\\n'.format(item['key']))\n",
    "        # Handle when there are no PDF attachments\n",
    "        elif not pdfs:\n",
    "            print('\\nNO PDFs {}\\n'.format(item['key']))\n",
    "        # Handle when there is more than one PDF attachment\n",
    "        elif len(pdfs) != 1:\n",
    "            print('\\nTOO MANY PDFs {}\\n'.format(item['key']))\n",
    "        # Save the PDF to the class directory\n",
    "        else:\n",
    "            doc = pdfs[0]\n",
    "            print(doc['data']['filename'])\n",
    "            zot.dump(doc['key'], '{}.pdf'.format(doc['key']), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collevatti et al. - 2013 - Stability of Brazilian seasonally dry forests unde.pdf\n",
      "Limitations-in-global-information-on-species-occurrences.pdf\n",
      "Hernandez-Triana et al. - 2015 - DNA barcoding as an aid for species identification.pdf\n",
      "Woodruff and Fasulo - Banana Root Borer, Cosmopolites sordidus (Germar)(.pdf\n",
      "Barnes - 2010 - A remarkable case of fiddler crab, Uca spp., alpha.pdf\n",
      "Burton et al. - 2012 - Hierarchical multi-species modeling of carnivore r.pdf\n",
      "TWEET et al. - NAME-BEARING FOSSIL TYPE SPECIMENS AND TAXA NAMED .pdf\n",
      "Rome et al. - 2015 - Caste differentiation and seasonal changes in Vesp.pdf\n",
      "Mateo et al. - 2010 - Effects of the number of presences on reliability .pdf\n",
      "FERRAZ et al. - 2012 - How species distribution mo-dels can improve cat c.pdf\n",
      "\n",
      "NO PDFs 6URCJSNP\n",
      "\n",
      "Brooks et al. - 2015 - Harnessing biodiversity and conservation knowledge.pdf\n"
     ]
    }
   ],
   "source": [
    "get_pdfs(output_dir, 'RSet_N1', 'Rel-Yes', group_id, user_key)\n",
    "get_pdfs(output_dir, 'RSet_N1', 'Rel-No', group_id, user_key)\n",
    "get_pdfs(output_dir, 'RSet_N2', 'Rel-Yes', group_id, user_key)\n",
    "get_pdfs(output_dir, 'RSet_N2', 'Rel-No', group_id, user_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Handle duplicate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that some files have both labels (Rel-Yes and Rel-No). We need to remove these files from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all PDF file names for a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_names(root, cls):\n",
    "    pattern = join('data', 'pdf', root, cls, '*.pdf')\n",
    "    paths = glob(pattern)\n",
    "    return [basename(p) for p in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move one copy of the file out of the way and delete the extra copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_duplicates(root):\n",
    "\n",
    "    rel_yes = set(file_names(root, 'Rel-Yes'))\n",
    "    rel_no = set(file_names(root, 'Rel-No'))\n",
    "    duplicates = rel_yes & rel_no\n",
    "\n",
    "    dup_root = join('data', 'pdf', 'duplicates')\n",
    "    os.makedirs(dup_root, exist_ok=True)\n",
    "\n",
    "    for duplicate in duplicates:\n",
    "        print(duplicate)\n",
    "        src = join('data', 'pdf', root, 'Rel-Yes', duplicate)\n",
    "        dst = join(dup_root, duplicate)\n",
    "        move(src, dst)\n",
    "        src = join('data', 'pdf', root, 'Rel-No', duplicate)\n",
    "        os.remove(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_duplicates('RSet_N1')\n",
    "move_duplicates('RSet_N2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert PDF files to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the PDF files to text. They will be placed into the given output directory. This utility depends on the external program \"xpdf\" specifically \"pdftotext\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text from the PDF ad write it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdf_to_text(output_dir, pdf_path):\n",
    "    txt_name = basename(pdf_path)\n",
    "    txt_name = splitext(txt_name)[0] + '.txt'\n",
    "    txt_path = join(output_dir, txt_name)\n",
    "    cmd = \"pdftotext '{}' '{}'\".format(pdf_path, txt_path)\n",
    "    try:\n",
    "        subprocess.check_call(cmd, shell=True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all of the PDFs and convert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_pdfs(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    pattern = join(input_dir, '*.pdf')\n",
    "    pdf_paths = glob(pattern)\n",
    "\n",
    "    for i, pdf_path in enumerate(pdf_paths, 1):\n",
    "        print('Converting:', pdf_path)\n",
    "        pdf_to_text(output_dir, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: data/pdf/RSet_N1/Rel-Yes/NFBFRJE3.pdf\n",
      "Converting: data/pdf/RSet_N1/Rel-Yes/7H3FB5AR.pdf\n",
      "Converting: data/pdf/RSet_N1/Rel-Yes/9FWZX3P8.pdf\n",
      "Converting: data/pdf/RSet_N1/Rel-No/HUK6N8SE.pdf\n",
      "Converting: data/pdf/RSet_N1/Rel-No/TDIW72GZ.pdf\n",
      "Converting: data/pdf/RSet_N1/Rel-No/PQ8MRSVV.pdf\n",
      "Converting: data/pdf/RSet_N2/Rel-Yes/U2BPDHGA.pdf\n",
      "Converting: data/pdf/RSet_N2/Rel-Yes/DT5FH8G5.pdf\n",
      "Converting: data/pdf/RSet_N2/Rel-Yes/DHW5ACU8.pdf\n",
      "Converting: data/pdf/RSet_N2/Rel-No/VR7BXTHD.pdf\n",
      "Converting: data/pdf/RSet_N2/Rel-No/IFJXWSER.pdf\n"
     ]
    }
   ],
   "source": [
    "convert_pdfs('data/pdf/RSet_N1/Rel-Yes', 'data/text/RSet_N1/Rel-Yes')\n",
    "convert_pdfs('data/pdf/RSet_N1/Rel-No', 'data/text/RSet_N1/Rel-No')\n",
    "\n",
    "convert_pdfs('data/pdf/RSet_N2/Rel-Yes', 'data/text/RSet_N2/Rel-Yes')\n",
    "convert_pdfs('data/pdf/RSet_N2/Rel-No', 'data/text/RSet_N2/Rel-No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_seed = 23578 # Fix the random seed for testing\n",
    "test_split = 0.2  # How much of the data to use for testing\n",
    "val_split = 0.2   # How much of the data to use for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files into the appropriate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_files(paths, cls):\n",
    "    \"\"\"Move files into the correct dirctories.\"\"\"\n",
    "\n",
    "    shuffle(paths)\n",
    "\n",
    "    val_idx = int(len(paths) * val_split)\n",
    "    test_idx = val_split + int(len(paths) * test_split)\n",
    "\n",
    "    for i, src in enumerate(paths):\n",
    "        if i < val_idx:\n",
    "            dir_name = 'val'\n",
    "        elif i < test_idx:\n",
    "            dir_name = 'test'\n",
    "        else:\n",
    "            dir_name = 'train'\n",
    "\n",
    "        dst = join('data', dir_name, cls, basename(src))\n",
    "        print(dst)\n",
    "        copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_files():\n",
    "    \"\"\"Split into training, validation, and test datasets.\"\"\"\n",
    "\n",
    "    os.makedirs('data/train/Rel-Yes', exist_ok=True)\n",
    "    os.makedirs('data/train/Rel-No', exist_ok=True)\n",
    "    os.makedirs('data/test/Rel-Yes', exist_ok=True)\n",
    "    os.makedirs('data/test/Rel-No', exist_ok=True)\n",
    "    os.makedirs('data/val/Rel-Yes', exist_ok=True)\n",
    "    os.makedirs('data/val/Rel-No', exist_ok=True)\n",
    "\n",
    "    rel_yes = glob('data/text/*/Rel-Yes/*.txt')\n",
    "    rel_no = glob('data/text/*/Rel-No/*.txt')\n",
    "\n",
    "    copy_files(rel_yes, 'Rel-Yes')\n",
    "    copy_files(rel_no, 'Rel-No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/val/Rel-Yes/DHW5ACU8.txt\n",
      "data/test/Rel-Yes/NFBFRJE3.txt\n",
      "data/train/Rel-Yes/9FWZX3P8.txt\n",
      "data/train/Rel-Yes/7H3FB5AR.txt\n",
      "data/train/Rel-Yes/U2BPDHGA.txt\n",
      "data/train/Rel-Yes/DT5FH8G5.txt\n",
      "data/val/Rel-No/VR7BXTHD.txt\n",
      "data/test/Rel-No/TDIW72GZ.txt\n",
      "data/train/Rel-No/HUK6N8SE.txt\n",
      "data/train/Rel-No/PQ8MRSVV.txt\n",
      "data/train/Rel-No/IFJXWSER.txt\n"
     ]
    }
   ],
   "source": [
    "seed(init_seed)\n",
    "split_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
